{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the labels of the raw imdb data\n",
    "imdb_dir='../Downloads/IMDB'\n",
    "train_dir=os.path.join(imdb_dir,'train')\n",
    "\n",
    "labels=[]\n",
    "texts=[]\n",
    "\n",
    "for label_type in ['neg','pos']:\n",
    "    dir_name=os.path.join(train_dir,label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:]=='.txt':\n",
    "            f=open(os.path.join(dir_name,fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type=='neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Working with one of the best Shakespeare sources, this film manages to be creditable to it's source, whilst still appealing to a wider audience.<br /><br />Branagh steals the film from under Fishburne's nose, and there's a talented cast on good form.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the raw text\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen=100\n",
    "num_words=10000\n",
    "training_samples=200 #since we are using pretrained word embeddings\n",
    "validation_samples=10000\n",
    "\n",
    "tokenizer=Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "sequences=tokenizer.texts_to_sequences(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[777,\n",
       " 16,\n",
       " 28,\n",
       " 4,\n",
       " 1,\n",
       " 115,\n",
       " 2278,\n",
       " 6887,\n",
       " 11,\n",
       " 19,\n",
       " 1025,\n",
       " 5,\n",
       " 27,\n",
       " 5,\n",
       " 42,\n",
       " 2425,\n",
       " 1861,\n",
       " 128,\n",
       " 2270,\n",
       " 5,\n",
       " 3,\n",
       " 6985,\n",
       " 308,\n",
       " 7,\n",
       " 7,\n",
       " 3383,\n",
       " 2373,\n",
       " 1,\n",
       " 19,\n",
       " 36,\n",
       " 463,\n",
       " 3169,\n",
       " 2,\n",
       " 222,\n",
       " 3,\n",
       " 1016,\n",
       " 174,\n",
       " 20,\n",
       " 49,\n",
       " 808]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens\n"
     ]
    }
   ],
   "source": [
    "word_index=tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding the sequences to equal length of 100\n",
    "data=pad_sequences(sequences,maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data tensor (25000, 100)\n",
      "shape of label tensor (25000,)\n"
     ]
    }
   ],
   "source": [
    "print('shape of data tensor',data.shape)\n",
    "print('shape of label tensor',labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "data=data[indices]\n",
    "labels=labels[indices]\n",
    "\n",
    "x_train=data[:10000]\n",
    "y_train=labels[:10000]\n",
    "\n",
    "x_val=data[10000:12000]\n",
    "y_val=labels[10000:12000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Embedding(10000,30,input_length=maxlen),\n",
    "    Flatten(),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 30)           300000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3001      \n",
      "=================================================================\n",
      "Total params: 303,001\n",
      "Trainable params: 303,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 140us/sample - loss: 0.6457 - accuracy: 0.6521 - val_loss: 0.5220 - val_accuracy: 0.7880\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 0.3852 - accuracy: 0.8539 - val_loss: 0.3605 - val_accuracy: 0.8530\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 0.2560 - accuracy: 0.9065 - val_loss: 0.3299 - val_accuracy: 0.8605\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 0.1852 - accuracy: 0.9366 - val_loss: 0.3291 - val_accuracy: 0.8555\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 70us/sample - loss: 0.1303 - accuracy: 0.9612 - val_loss: 0.3341 - val_accuracy: 0.8610\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 69us/sample - loss: 0.0858 - accuracy: 0.9780 - val_loss: 0.3436 - val_accuracy: 0.8605\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 69us/sample - loss: 0.0533 - accuracy: 0.9896 - val_loss: 0.3623 - val_accuracy: 0.8530\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 80us/sample - loss: 0.0301 - accuracy: 0.9960 - val_loss: 0.3847 - val_accuracy: 0.8485\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 72us/sample - loss: 0.0158 - accuracy: 0.9985 - val_loss: 0.4159 - val_accuracy: 0.8440\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 69us/sample - loss: 0.0079 - accuracy: 0.9995 - val_loss: 0.4409 - val_accuracy: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13cdeedd8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=10,batch_size=32,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=Sequential([\n",
    "    Embedding(10000,50,input_length=maxlen),\n",
    "    Flatten(),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 134us/sample - loss: 0.6223 - accuracy: 0.6796 - val_loss: 0.4692 - val_accuracy: 0.8120\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 84us/sample - loss: 0.3403 - accuracy: 0.8709 - val_loss: 0.3457 - val_accuracy: 0.8545\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 82us/sample - loss: 0.2189 - accuracy: 0.9229 - val_loss: 0.3278 - val_accuracy: 0.8605\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 83us/sample - loss: 0.1410 - accuracy: 0.9587 - val_loss: 0.3350 - val_accuracy: 0.8620\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 83us/sample - loss: 0.0818 - accuracy: 0.9809 - val_loss: 0.3556 - val_accuracy: 0.8565\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 92us/sample - loss: 0.0419 - accuracy: 0.9933 - val_loss: 0.3807 - val_accuracy: 0.8480\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 90us/sample - loss: 0.0187 - accuracy: 0.9982 - val_loss: 0.4092 - val_accuracy: 0.8475\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 90us/sample - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.4501 - val_accuracy: 0.8460\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.5035 - val_accuracy: 0.8395\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 86us/sample - loss: 8.4768e-04 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.8410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f28dcf8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train,y_train,epochs=10,batch_size=32,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
